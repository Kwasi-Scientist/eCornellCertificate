{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-f73a8eff8b7c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-f73a8eff8b7c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <h2>About this Exercise</h2>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def l2distanceSlow(X,Z=None):\n",
    "    if Z is None:\n",
    "        Z = X\n",
    "    \n",
    "    n, d = X.shape     # dimension of X\n",
    "    m= Z.shape[0]   # dimension of Z\n",
    "    D=np.zeros((n,m)) # allocate memory for the output matrix\n",
    "    for i in range(n):     # loop over vectors in X\n",
    "        for j in range(m): # loop over vectors in Z\n",
    "            D[i,j]=0.0; \n",
    "            for k in range(d): # loop over dimensions\n",
    "                D[i,j]=D[i,j]+(X[i,k]-Z[j,k])**2; # compute l2-distance between the ith and jth vector\n",
    "            D[i,j]=np.sqrt(D[i,j]); # take square root\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.random.rand(700,100)\n",
    "print(\"Running the naive version for the...\")\n",
    "%time Dslow=l2distanceSlow(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Exercises</h2>\n",
       "\n",
       "<p>In the following three exercises, you'll take the steps necessary to implement the euclidean distance function without loops.</p>\n",
       "\n",
       "<h3>Exercise 1: Inner-Product Matrix</h3>\n",
       "\n",
       "<p>Show that the Inner-Product Matrix (Gram matrix) can be expressed in terms of pure matrix multiplication.\n",
       "\n",
       "$$\tG_{ij}=\\mathbf{x}_i\\mathbf{z}_j^\\top $$\n",
       "\n",
       "Once you are done with the derivation, implement the function <strong><code>innerproduct</code></strong>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h2>Exercises</h2>\n",
    "\n",
    "<p>In the following three exercises, you'll take the steps necessary to implement the euclidean distance function without loops.</p>\n",
    "\n",
    "<h3>Exercise 1: Inner-Product Matrix</h3>\n",
    "\n",
    "<p>Show that the Inner-Product Matrix (Gram matrix) can be expressed in terms of pure matrix multiplication.\n",
    "\n",
    "$$\tG_{ij}=\\mathbf{x}_i\\mathbf{z}_j^\\top $$\n",
    "\n",
    "Once you are done with the derivation, implement the function <strong><code>innerproduct</code></strong>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerproduct(X,Z=None):\n",
    "    # function innerproduct(X,Z)\n",
    "    #\n",
    "    # Computes the inner-product matrix.\n",
    "    # Syntax:\n",
    "    # D=innerproduct(X,Z)\n",
    "    # Input:\n",
    "    # X: nxd data matrix with n vectors (rows) of dimensionality d\n",
    "    # Z: mxd data matrix with m vectors (rows) of dimensionality d\n",
    "    #\n",
    "    # Output:\n",
    "    # Matrix G of size nxm\n",
    "    # G[i,j] is the inner-product between vectors X[i,:] and Z[j,:]\n",
    "    #\n",
    "    # call with only one input:\n",
    "    # innerproduct(X)=innerproduct(X,X)\n",
    "    #\n",
    "    if Z is None: # case when there is only one input (X)\n",
    "        Z=X;\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #X = np.array([n,d])\n",
    "   # Z = np.array([m,])\n",
    "    #n,d = X.shape #dimensions of X\n",
    "    #m = Z.shape[0] #dimension of Z\n",
    "    \n",
    "    G= np.zeros((X.shape[0],Z.shape[0])) #reserve memory for matrix D\n",
    "    G = np.dot(X, Z.T)\n",
    "    return G\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this self-test cell to check your code\n",
    "\n",
    "def innerprod_0():\n",
    "    # test the output dimensions of innerproduct with one input matrix\n",
    "    X = np.random.rand(700,10) # define 700 random inputs X\n",
    "    test = (innerproduct(X).shape==700,700)    # check if inner-product matrix has dimension 700x700\n",
    "    return test\n",
    "\n",
    "def innerprod_1():\n",
    "    # test the output dimensions of innerproduct with two matrices\n",
    "    X = np.random.rand(700,10) # define 700 random inputs X\n",
    "    Z = np.random.rand(200,10) # define 200 random inputs Z \n",
    "    test=(innerproduct(X,Z).shape ==(700,200)) # check if inner-product matrix has dimensions 700x200\n",
    "    return test\n",
    "\n",
    "def innerprod_2():\n",
    "    X = np.random.rand(700,100) # define 700 random inputs X\n",
    "    IP1 = innerproduct(X) # compute inner-product matrix with YOUR code\n",
    "    IP2 = innerproduct_grader(X) # compute inner-product matrix with OUR code\n",
    "    test = np.linalg.norm(IP1 - IP2) # compute the norm of the difference\n",
    "    return test<1e-5 # this norm should be essentially 0\n",
    "\n",
    "def innerprod_3():\n",
    "    X = np.random.rand(700,100) # define 700 random inputs X\n",
    "    Z = np.random.rand(300,100) # define 300 random inputs X\n",
    "    IP1 = innerproduct(X,Z) # compute inner-product matrix with YOUR code\n",
    "    IP2 = innerproduct_grader(X,Z) # compute inner-product matrix with OUR code\n",
    "    test = np.linalg.norm(IP1 - IP2) # compute the norm of the difference\n",
    "    return test<1e-5 # this norm should be essentially 0\n",
    "\n",
    "\n",
    "runtest(innerprod_0,'innerprod_0')\n",
    "runtest(innerprod_1,'innerprod_1')\n",
    "runtest(innerprod_2,'innerprod_2')\n",
    "runtest(innerprod_3,'innerprod_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Exercise 2: Derive the Distance Matrix</h3>\n",
       "\n",
       "Let us define two new matrices $S,R\\in{\\cal R}^{n\\times m}$ \n",
       "\t\t$$S_{ij}=\\mathbf{x}_i\\mathbf{x}_i^\\top, \\ \\ R_{ij}=\\mathbf{z}_j\\mathbf{z}_j^\\top.$$\n",
       " \tShow that the <em>squared</em>-euclidean matrix $D^2\\in{\\cal R}^{n\\times m}$, defined as\n",
       "\t\t$$D^2_{ij}=(\\mathbf{x}_i-\\mathbf{z}_j)(\\mathbf{x}_i-\\mathbf{z}_j)^\\top,$$\n",
       "\tcan be expressed as a linear combination of the matrix $S, G, R$. (Hint: It might help to first express $D^2_{ij}$ in terms of inner-products.) What do you need to do to obtain the true Euclidean distance matrix $D$?</p></td>\n",
       "\t\n",
       "<p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3>Exercise 2: Derive the Distance Matrix</h3>\n",
    "\n",
    "Let us define two new matrices $S,R\\in{\\cal R}^{n\\times m}$ \n",
    "\t\t$$S_{ij}=\\mathbf{x}_i\\mathbf{x}_i^\\top, \\ \\ R_{ij}=\\mathbf{z}_j\\mathbf{z}_j^\\top.$$\n",
    " \tShow that the <em>squared</em>-euclidean matrix $D^2\\in{\\cal R}^{n\\times m}$, defined as\n",
    "\t\t$$D^2_{ij}=(\\mathbf{x}_i-\\mathbf{z}_j)(\\mathbf{x}_i-\\mathbf{z}_j)^\\top,$$\n",
    "\tcan be expressed as a linear combination of the matrix $S, G, R$. (Hint: It might help to first express $D^2_{ij}$ in terms of inner-products.) What do you need to do to obtain the true Euclidean distance matrix $D$?</p></td>\n",
    "\t\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Exercise 3: Implement <code>l2distance</code></h3>\n",
       "\n",
       "<p>Implement the function <strong><code>l2distance</code></strong>, which computes the Euclidean distance matrix $D$ without a single loop. (Hint: Make sure that when you take the square root of the squared distance matrix, ensure that all entries are non-negative. Sometimes very small numvers can be non-negative due to numerical precision, you can just set them to 0.)</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3>Exercise 3: Implement <code>l2distance</code></h3>\n",
    "\n",
    "<p>Implement the function <strong><code>l2distance</code></strong>, which computes the Euclidean distance matrix $D$ without a single loop. (Hint: Make sure that when you take the square root of the squared distance matrix, ensure that all entries are non-negative. Sometimes very small numvers can be non-negative due to numerical precision, you can just set them to 0.)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def l2distance(X,Z=None):\n",
    "    # function D=l2distance(X,Z)\n",
    "    #\n",
    "    # Computes the Euclidean distance matrix.\n",
    "    # Syntax:\n",
    "    # D=l2distance(X,Z)\n",
    "    # Input:\n",
    "    # X: nxd data matrix with n vectors (rows) of dimensionality d\n",
    "    # Z: mxd data matrix with m vectors (rows) of dimensionality d\n",
    "    #\n",
    "    # Output:\n",
    "    # Matrix D of size nxm\n",
    "    # D(i,j) is the Euclidean distance of X(i,:) and Z(j,:)\n",
    "    #\n",
    "    # call with only one input:\n",
    "    # l2distance(X)=l2distance(X,X)\n",
    "    #\n",
    "    if Z is None:\n",
    "        Z=X\n",
    "\n",
    "    n,d1=X.shape\n",
    "    m,d2=Z.shape\n",
    "    assert (d1==d2), \"Dimensions of input vectors must match!\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #first reserve the memory for the D matrix\n",
    "    D = np.zeros((X.shape[0],Z.shape[0]))\n",
    "    #estabilish the innerproduct or dot productD\n",
    "    \n",
    "    #note X[0] is an array\n",
    "    #this is soooo close\n",
    "    #D = np.sqrt(np.sum( (X[0]-Z[0])**2) - np.sum( (X[0].T-Z[0].T**2)))\n",
    "    G = np.dot(X,Z.T)\n",
    "    #D = np.sum(np.square(X)) + np.sum(np.square(Z)) - 2*G\n",
    "    \n",
    "    #S = np.dot(X[:,...],X[:,...].T) #for S we want to square the value of each training row\n",
    "    S = np.square(X[:,...])\n",
    "    S = np.sum(S,1)\n",
    "    S = np.expand_dims(S,1)\n",
    "    #R = np.dot(Z[:,...],Z[:,...].T) #for R we want to square the value for each testing column\n",
    "    R = Z[...,:]\n",
    "    R = np.square(R)\n",
    "    R = np.sum(R,1)\n",
    "    \n",
    "    #S and R should both be 1 D Vectors\n",
    "    \n",
    "    R = np.expand_dims(R,0)\n",
    "    D1 =  R -2*G\n",
    "    Dfinal = D1 + S\n",
    "    Dfinal = np.sqrt(Dfinal)\n",
    "    #Dfinal = np.sqrt(np.absolute(Dfinal))\n",
    "    #D2 = np.square(X - Z.T)\n",
    "    #D2R = np.sqrt(D2)\n",
    "    #D3 = np.sqrt(G)\n",
    "\n",
    "    #D4 = np.square((n-m)+(d1-d2))\n",
    "    #D4S = np.sqrt(D4)\n",
    "    #S = np.sum(X,X.T)**2\n",
    "    #S = np.dot(X, X.T)\n",
    "    #R = np.sum((Z -Z.T))**2\n",
    "    \n",
    "    #D = S + 2*G\n",
    "    #print('S.shape', S.shape)\n",
    "    #print('X[1]', X.shape[1])\n",
    "    #print('Dshape', D.shape)\n",
    "    #print('D', D)\n",
    "    #print('D2', D2.shape)\n",
    "    #print('D3', D3)\n",
    "    #print('n', n)\n",
    "    #print('m', m)\n",
    "    #print('S', S.shape)\n",
    "    #print('R', R.shape)\n",
    "    #print('Shape', X[:,...].shape)\n",
    "    #print('D1', D1.shape)\n",
    "    #print('Dfinal', Dfinal)\n",
    "    return Dfinal\n",
    "\n",
    "\n",
    "\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "#X = np.random.rand(700,100)\n",
    "#Z = None#np.random.rand(800,100)\n",
    "#l2distance(X,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this self-test cell to check your code\n",
    "\n",
    "def distance_accuracy(): \n",
    "    X = np.random.rand(700,100) # define random inputs\n",
    "    D1 = l2distance(X) # compute distances from your solutions\n",
    "    D2 = l2distance_grader(X) #compute distance from ground truth\n",
    "    test = np.linalg.norm(D1 - D2) # compare the two\n",
    "    return test<1e-5 # difference should be small\n",
    "\n",
    "def distance_squareroot():  \n",
    "    X = np.random.rand(700,100) # define random inputs\n",
    "    D1 = l2distance(X) # compute distances from your solutions\n",
    "    D2sq = l2distance_grader(X)**2 #compute distance from ground truth *but square them*\n",
    "    test = np.linalg.norm(D1 - D2sq) # compare the two\n",
    "    return test>1e-5 # difference should be big\n",
    "\n",
    "def dimensions():\n",
    "    X = np.random.rand(700,100) # define random inputs\n",
    "    Z = np.random.rand(800,100) # define random inputs\n",
    "    n,d1=X.shape\n",
    "    m,d2=Z.shape    \n",
    "    D1 = l2distance(X,Z) # compute distances from your solutions\n",
    "    o1,o2=D1.shape\n",
    "    return (o1==n) and (o2==m)\n",
    "\n",
    "def matrix_dist_accuracy():\n",
    "    X = np.random.rand(700,100)\n",
    "    Z = np.random.rand(300,100)\n",
    "    D1Z = l2distance(X,Z)\n",
    "    D2Z = l2distance_grader(X,Z)\n",
    "    test = np.linalg.norm(D1Z - D2Z)\n",
    "    return test<1e-5\n",
    "\n",
    "runtest(distance_accuracy,'distance_accuracy')\n",
    "runtest(distance_squareroot,'distance_squareroot')\n",
    "runtest(dimensions,'dimensions')\n",
    "runtest(matrix_dist_accuracy,'matrix_dist_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "current_time = lambda: int(round(time.time() * 1000))\n",
    "\n",
    "X=np.random.rand(700,100)\n",
    "Z=np.random.rand(300,100)\n",
    "\n",
    "print(\"Running the naÃ¯ve version...\")\n",
    "before = current_time()\n",
    "Dslow=l2distanceSlow(X)\n",
    "after = current_time()\n",
    "t_slow = after - before\n",
    "print(\"{:2.0f} ms\".format(t_slow))\n",
    "\n",
    "print(\"Running the vectorized version...\")\n",
    "before = current_time()\n",
    "Dfast=l2distance(X)\n",
    "after = current_time()\n",
    "t_fast = after - before\n",
    "print(\"{:2.0f} ms\".format(t_fast))\n",
    "\n",
    "\n",
    "speedup = t_slow / t_fast\n",
    "print(\"The two methods should deviate by very little: {:05.6f}\".format(norm(Dfast-Dslow)))\n",
    "print(\"but your NumPy code was {:05.2f} times faster!\".format(speedup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD A FACIAL RECOGNITION SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import sys\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "from helper import *\n",
    "\n",
    "\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <p>We will refer to the training vectors as <b>xTr</b> with labels <b>yTr</b>. Our testing vectors are <b>xTe</b> with labels <b>yTe</b>.\n",
    "# As a reminder, to predict the label or class of an image in <b>xTe</b>, we will look for the <i>k</i>-nearest neighbors in <b>xTr</b> and predict a label based on their labels in <b>yTr</b>. For evaluation, we will compare these labels against the true labels provided in <b>yTe</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr,yTr,xTe,yTe=loaddata(\"faces.mat\")\n",
    "\n",
    "plt.figure(figsize=(11,8))\n",
    "plotfaces(xTr[:9, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <h3>Part 1: Implement <b><code>findknn</code></b> [Graded]</h3>\n",
    "\n",
    "# <p>Implement the function <b><code>findknn</code></b>, which should find the $k$ nearest neighbors of a set of vectors within a given training data set. The call of:</p>\n",
    "# <pre>\n",
    "#  [I,D]=findknn(xTr,xTe,k);\n",
    "# </pre> \n",
    "# <p>should result in two matrices $I$ and $D$, both of dimensions $k\\times n$, where $n$ is the number of input vectors in <code>xTe</code>. The matrix $I(i,j)$ is the index of the $i^{th}$ nearest neighbor of the vector $xTe(j,:)$.</p>\n",
    "# <p>\n",
    "# So, for example, if we set <code>i=I(1,3)</code>, then <code>xTr(i,:)</code> is the first nearest neighbor of vector <code>xTe(3,:)</code>. The second matrix $D$ returns the corresponding distances. So $D(i,j)$ is the distance of $xTe(j,:)$ to its $i^{th}$ nearest neighbor.</p>\n",
    "# <p>You can use the function <code>l2distance</code> from the previous exercise (which is readily available to you.) You may find <code>np.argsort(D,0)</code> and <code>np.sort(D,0)</code> useful when implementing <code>findknn</code>. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findknn(xTr,xTe,k):\n",
    "    \"\"\"\n",
    "    function [indices,dists]=findknn(xTr,xTe,k);\n",
    "    \n",
    "    Finds the k nearest neighbors of xTe in xTr.\n",
    "    \n",
    "    Input:\n",
    "    xTr = nxd input matrix with n row-vectors of dimensionality d\n",
    "    xTe = mxd input matrix with m row-vectors of dimensionality d\n",
    "    k = number of nearest neighbors to be found\n",
    "    \n",
    "    Output:\n",
    "    indices = kxm matrix, where indices(i,j) is the i^th nearest neighbor of xTe(j,:)\n",
    "    dists = Euclidean distances to the respective nearest neighbors\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #FIRST reserve space in memory for distance and index matricies\n",
    "    indices = np.zeros((xTr.shape[0], xTe.shape[0]))\n",
    "    dists = np.zeros((xTr.shape[0], xTe.shape[0]))\n",
    "    #define the gram Marix (dot product), G\n",
    "    G = np.dot(xTr, xTe.T)\n",
    "    \n",
    "    \n",
    "    #define L2distance/Euclidean distance\n",
    "\n",
    "    \n",
    "    #G = np.dot(X,Z.T)\n",
    "    S = np.square(xTr[:,...])\n",
    "    S = np.sum(S,1)\n",
    "    S = np.expand_dims(S,1)\n",
    "    R = xTe[...,:]\n",
    "    R = np.square(R)\n",
    "    R = np.sum(R,1)\n",
    "    \n",
    "    #S and R should both be 1 D Vectors\n",
    "    \n",
    "    R = np.expand_dims(R,0)\n",
    "    D1 =  R -2*G\n",
    "    Dfinal = D1 + S\n",
    "    Dfinal = np.sqrt(Dfinal)\n",
    "    \n",
    "    \n",
    "    dists = l2distance(xTr, xTe)\n",
    "    dists_sorted = np.sort(Dfinal,0)\n",
    "    dists_sorted_k = dists_sorted[:k,...]\n",
    "    #print('l2sortedk', dists_sorted_k.shape)\n",
    "    \n",
    "    \n",
    "    #Define index matrix\n",
    "    #indices not quite right\n",
    "    #neighbors = [dists[i][1] for i in range(k)]\n",
    "    #print('neighbors', neighbors.shape)\n",
    "    #indices = np.array([i for i in np.nditer(dists)]).reshape(500,300)\n",
    "    #indices = np.sort(indices)\n",
    "    #indices = np.argwhere(dists_sorted_k.shape == (5, 300))\n",
    "    #index1 = np.asarray(np.where(dists_sorted_k[1,:]))\n",
    "    #index2 = np.asarray(np.where(dists_sorted_k[0, :k])).T #gives index values\n",
    "    #indices = index1 + index2\n",
    "    indices = np.argsort(dists_sorted_k)\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(\"index1\", index1)\n",
    "    #print(\"index2\", index2)\n",
    "    #print('indices', indices)\n",
    "    #print('dists', dists_sorted_k.shape)\n",
    "    #print('Dfinal', Dfinal)\n",
    "    \n",
    "    return indices, dists_sorted_k\n",
    "    return None\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "xTe = np.random.rand(300,10)\n",
    "findknn(xTr,xTe, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this self-test cell to check your code\n",
    "\n",
    "def knn_0():\n",
    "    # checking output types\n",
    "    xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "    xTe = np.random.rand(300,10) # defining 300 testing data points\n",
    "    Ig,Dg = findknn(xTr,xTe,5) # compute indices and distances to the 5- nearest neighbors \n",
    "    # check if Ig is a matrix of integers, Dg a matrix of floats\n",
    "    test=(type(Ig)==np.ndarray)  & (type(Ig)==np.ndarray) & ((type(Dg[0][0])==np.float64) or (type(Dg[0][0])==np.float32)) & ((type(Dg[0][0])==np.float64) or (type(Dg[0][0])==np.float32))\n",
    "    return test\n",
    "\n",
    "def knn_1():\n",
    "    # checking output dimensions\n",
    "    xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "    xTe = np.random.rand(300,10) # defining 300 testing data points\n",
    "    Ig,Dg = findknn(xTr,xTe,5) # compute indices and distances to the 5- nearest neighbors \n",
    "    test=(Ig.shape==(5,300)) & (Dg.shape==(5,300)) # test if output dimensions are correct\n",
    "    return test\n",
    "\n",
    "def knn_2():\n",
    "    # checking 1-NN accuracy\n",
    "    xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "    xTe = np.random.rand(300,10) # defining 300 testing data points\n",
    "    Ig,Dg = findknn_grader(xTr,xTe,1) # compute indices and distances to the nearest neighbors with *our* code\n",
    "    Is,Ds = findknn(xTr,xTe,1) # Use *your* code\n",
    "    test = np.linalg.norm(Ig - Is) + np.linalg.norm(Dg - Ds) # compare results\n",
    "    return test<1e-5 \n",
    "\n",
    "def knn_3():\n",
    "    # checking 3-NN accuracy\n",
    "    xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "    xTe = np.random.rand(300,10) # defining 300 testing data points\n",
    "    Ig,Dg = findknn_grader(xTr,xTe,3) # compute indices and distances to the 3-nearest neighbors with *our* code\n",
    "    Is,Ds = findknn(xTr,xTe,3) # Use *your* code\n",
    "    test = np.linalg.norm(Ig - Is) + np.linalg.norm(Dg - Ds) # compare results\n",
    "    return test<1e-5 \n",
    "\n",
    "runtest(knn_0,'knn_0')\n",
    "runtest(knn_1,'knn_1')\n",
    "runtest(knn_2,'knn_2')\n",
    "runtest(knn_3,'knn_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualize_knn_2D(findknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "visualize_knn_images(findknn, imageType='faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <h3>Part 2: Implement <b><code>accuracy</code></b> [Graded]</h3>\n",
    "\n",
    "# <p>The function <b><code>accuracy</code></b> should compute the accuracy of a classifier. The call of:</p>\n",
    "# <pre>\n",
    "#   result=accuracy(truth,preds);\n",
    "# </pre>\n",
    "# <p>should output the <b>accuracy</b> in variable <code>result</code>. The input variables <code>truth</code> and <code>preds</code> should contain vectors of true and predicted labels respectively.</p>\n",
    "# <p>For example, the call:</p>\n",
    "# <pre>\n",
    "# >> accuracy([1 2 1 2],[1 2 1 1])\n",
    "# </pre>\n",
    "# <p>should return an accuracy of 0.75. Here, the true labels are 1,2,1,2 and the predicted labels are 1,2,1,1. So the first three examples are classified correctly, and the last one is wrong --- 75% accuracy.</p>\n",
    "# <p>You may find the following functions helpful: <code>flatten()</code>, <code>np.mean()</code> and <code>np.abs()</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(truth,preds):\n",
    "    \"\"\"\n",
    "    function output=accuracy(truth,preds)         \n",
    "    Analyzes the accuracy of a prediction against the ground truth\n",
    "    \n",
    "    Input:\n",
    "    truth = n-dimensional vector of true class labels\n",
    "    preds = n-dimensional vector of predictions\n",
    "    \n",
    "    Output:\n",
    "    accuracy = scalar (percent of predictions that are correct)\n",
    "    \"\"\"\n",
    "    \n",
    "    truth = truth.flatten()\n",
    "    preds = preds.flatten()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    correct = 0\n",
    " \n",
    "    sub = truth - preds\n",
    "    subzeros = np.count_nonzero(sub)\n",
    "    truthlen = len(truth)\n",
    "    correct = truthlen - subzeros\n",
    "    ans = (float(correct)/truthlen)\n",
    "    ans = np.float64(ans)\n",
    "    #print('subzeros', subzeros)\n",
    "    #print('truthlen', truthlen)\n",
    "    #print('correct',correct)\n",
    "    #print('ans', ans.dtype)\n",
    "    \n",
    "    return ans\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "#truth = np.array([1, 2, 3, 4])\n",
    "#preds = np.array([1, 2, 3, 0])\n",
    "#accuracy(truth,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this self-test cell to check your code\n",
    "\n",
    "def accuracy_test0():\n",
    "    # check type of output is correct\n",
    "    truth = np.array([1, 2, 3, 4])\n",
    "    preds = np.array([1, 2, 3, 0])\n",
    "    return type(accuracy(truth,preds))==np.float64\n",
    "\n",
    "def accuracy_test1():\n",
    "    # accuracy check on 4 sample data\n",
    "    truth = np.array([1, 2, 3, 4]) # define truth \n",
    "    preds = np.array([1, 2, 3, 0]) # define preds\n",
    "    return abs(accuracy(truth,preds) - 0.75)<1e-10 # check if accuracy is correct\n",
    "\n",
    "def accuracy_test2():\n",
    "    # accuracy check on random samples\n",
    "    p=np.random.rand(1,1000); # define random string of [0,1] as truth\n",
    "    truth=np.int16(p>0.5)\n",
    "    p2=p+np.random.randn(1,1000)*0.1; # define very similar version as preds\n",
    "    preds=np.int16(p2>0.5)\n",
    "    return abs(accuracy(truth,preds) - accuracy_grader(truth,preds))<1e-10 # check if accuracy is correct\n",
    "\n",
    "runtest(accuracy_test0,'accuracy_test0 (types)')\n",
    "runtest(accuracy_test1,'accuracy_test1 (exactness)')\n",
    "runtest(accuracy_test2,'accuracy_test2 (exactness)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Part 3: Implement <b><code>knnclassifier</code></b> [Graded]</h3>\n",
       "\n",
       "<p>Implement the function <b><code>knnclassifier</code></b>, which should perform $k$ nearest neighbor classification on a given test data set. The call:</p>\n",
       "<pre>preds=knnclassifier(xTr,yTr,xTe,k)</pre>\n",
       "<p>should output the predictions for the data in <code>xTe</code> i.e. <code>preds[i]</code> will contain the prediction for <code>xTe[i,:]</code>.</p>\n",
       "\n",
       "<p>You may find it helpful to use <code>flatten()</code> in the implementation of this function. It will also be useful to  refer back to the mode function you implemented in <a href=\"https://lms.ecornell.com/courses/1451693/modules/items/16187695\">Additional NumPy Exercises</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3>Part 3: Implement <b><code>knnclassifier</code></b> [Graded]</h3>\n",
    "\n",
    "<p>Implement the function <b><code>knnclassifier</code></b>, which should perform $k$ nearest neighbor classification on a given test data set. The call:</p>\n",
    "<pre>preds=knnclassifier(xTr,yTr,xTe,k)</pre>\n",
    "<p>should output the predictions for the data in <code>xTe</code> i.e. <code>preds[i]</code> will contain the prediction for <code>xTe[i,:]</code>.</p>\n",
    "\n",
    "<p>You may find it helpful to use <code>flatten()</code> in the implementation of this function. It will also be useful to  refer back to the mode function you implemented in <a href=\"https://lms.ecornell.com/courses/1451693/modules/items/16187695\">Additional NumPy Exercises</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnclassifier(xTr,yTr,xTe,k):\n",
    "    \"\"\"\n",
    "    function preds=knnclassifier(xTr,yTr,xTe,k);\n",
    "    \n",
    "    k-nn classifier \n",
    "    \n",
    "    Input:\n",
    "    xTr = nxd input matrix with n row-vectors of dimensionality d\n",
    "    xTe = mxd input matrix with m row-vectors of dimensionality d\n",
    "    k = number of nearest neighbors to be found\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    preds = predicted labels, ie preds(i) is the predicted label of xTe(i,:)\n",
    "    \"\"\"\n",
    "    # fix array shapes\n",
    "    yTr = yTr.flatten()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    I,D = findknn(xTr,xTe,k)\n",
    "\n",
    "    labels =np.multiply(I.flatten(),yTr)\n",
    "    labels = np.array(labels)\n",
    "    print('labels', labels.dtype)\n",
    "    print('yTr', yTr.dtype)\n",
    "    print('[I]', I.flatten().dtype)\n",
    "    print('D', D)\n",
    "    print('mindist', np.amin(D))\n",
    "    \n",
    "    #print('dist', D)\n",
    "    \n",
    "    return labels\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "y = np.array([1,1,2,2])\n",
    "preds=knnclassifier(X,y,X,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this self-test cell to check your code\n",
    "\n",
    "def knn_classifier_test0():\n",
    "    # test if output is a numpy array, and of the right length\n",
    "    X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "    y = np.array([1,1,2,2])\n",
    "    preds=knnclassifier(X,y,X,1)\n",
    "    return type(preds)==np.ndarray and preds.shape==(4,)\n",
    "\n",
    "\n",
    "def knn_classifier_test1():\n",
    "    X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "    y = np.array([1,1,2,2])\n",
    "    np.testing.assert_allclose(knnclassifier(X,y,X,1),y)\n",
    "    return np.testing.assert_allclose\n",
    "\n",
    "\n",
    "def knn_classifier_test2():\n",
    "    X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "    y = np.array([1,1,2,2])\n",
    "    y2 = np.array([2,2,1,1])\n",
    "    return np.array_equal(knnclassifier(X,y,X,3),y2)\n",
    "\n",
    "def knn_classifier_test3():\n",
    "    X = np.array([[-4,-3,-2,2,3,4]]).T\n",
    "    y = np.array([1,1,1,2,2,2])\n",
    "    X2 = np.array([[-1,1]]).T\n",
    "    y2 = np.array([1,2])\n",
    "    return np.array_equal(knnclassifier(X,y,X2,2),y2)\n",
    "\n",
    "def knn_classifier_test4():\n",
    "    X = np.array([[-4,-3,-2,2,3,4]]).T\n",
    "    y = np.array([1,1,1,2,2,2])\n",
    "    X2 = np.array([[0,1]]).T\n",
    "    y2 = np.array([1,2])\n",
    "    y3 = np.array([2,2])\n",
    "    return np.array_equal(knnclassifier(X,y,X2,2),y2) or np.array_equal(knnclassifier(X,y,X2,2),y3)\n",
    "\n",
    "def knn_classifier_test5():\n",
    "    X = np.random.rand(4,4)\n",
    "    y = np.array([1,2,2,2])\n",
    "    return accuracy(knnclassifier(X,y,X,1),y) == 1\n",
    "\n",
    "def knn_classifier_test6():\n",
    "    X = np.random.rand(4,4)\n",
    "    y = np.array([1,2,1,2])\n",
    "    return accuracy(knnclassifier(X,y,X,1),y) == 1\n",
    "\n",
    "def knn_classifier_test7():\n",
    "    X = np.random.rand(10,100)\n",
    "    y = np.round(np.random.rand(10)).astype('int')\n",
    "    return accuracy(knnclassifier(X,y,X,1),y) == 1\n",
    "\n",
    "runtest(knn_classifier_test1,'knn_classifier_test1')\n",
    "runtest(knn_classifier_test2,'knn_classifier_test2')\n",
    "runtest(knn_classifier_test3,'knn_classifier_test3')\n",
    "runtest(knn_classifier_test4,'knn_classifier_test4')\n",
    "runtest(knn_classifier_test5,'knn_classifier_test5')\n",
    "runtest(knn_classifier_test6,'knn_classifier_test6')\n",
    "runtest(knn_classifier_test7,'knn_classifier_test7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3><b>Part 4: Calculate Accuracy</b></h3>\n",
       "\n",
       "<p>The following script runs your $k$-nearest neighbor classifier over the faces and digits data set. The faces data set has $40$ classes and the digits data set has $10$. What classification accuracy would you expect from a random classifier?</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3><b>Part 4: Calculate Accuracy</b></h3>\n",
    "\n",
    "<p>The following script runs your $k$-nearest neighbor classifier over the faces and digits data set. The faces data set has $40$ classes and the digits data set has $10$. What classification accuracy would you expect from a random classifier?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Face Recognition: (1-nn)\")\n",
    "xTr,yTr,xTe,yTe=loaddata(\"faces.mat\") # load the data\n",
    "t0 = time.time()\n",
    "preds = knnclassifier(xTr,yTr,xTe,1)\n",
    "result=accuracy(yTe,preds)\n",
    "t1 = time.time()\n",
    "print(\"You obtained %.2f%% classification acccuracy in %.4f seconds\\n\" % (result*100.0,t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
